{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spam Filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv(\"./datasets/spam_or_not_spam.csv\")\n",
    "X_data = data['email'].astype(str)\n",
    "y_data = data['label'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample email:   date wed NUMBER aug NUMBER NUMBER NUMBER NUMBER NUMBER from chris garrigues cwg dated NUMBER NUMBERfaNUMBERd deepeddy com message id NUMBER NUMBER tmda deepeddy vircio com i can t reproduce this error for me it is very repeatable like every time without fail this is the debug log of the pick happening NUMBER NUMBER NUMBER pick_it exec pick inbox list lbrace lbrace subject ftp rbrace rbrace NUMBER NUMBER sequence mercury NUMBER NUMBER NUMBER exec pick inbox list lbrace lbrace subject ftp rbrace rbrace NUMBER NUMBER sequence mercury NUMBER NUMBER NUMBER ftoc_pickmsgs NUMBER hit NUMBER NUMBER NUMBER marking NUMBER hits NUMBER NUMBER NUMBER tkerror syntax error in expression int note if i run the pick command by hand delta pick inbox list lbrace lbrace subject ftp rbrace rbrace NUMBER NUMBER sequence mercury NUMBER hit that s where the NUMBER hit comes from obviously the version of nmh i m using is delta pick version pick nmh NUMBER NUMBER NUMBER compiled on URL at sun mar NUMBER NUMBER NUMBER NUMBER ict NUMBER and the relevant part of my mh_profile delta mhparam pick seq sel list since the pick command works the sequence actually both of them the one that s explicit on the command line from the search popup and the one that comes from mh_profile do get created kre ps this is still using the version of the code form a day ago i haven t been able to reach the cvs repository today local routing issue i think _______________________________________________ exmh workers mailing list exmh workers URL URL \n",
      "is it spam? :  0\n"
     ]
    }
   ],
   "source": [
    "print(\"sample email: \", X_data.values[0])\n",
    "print(\"is it spam? : \", y_data.values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Object: 이메일을 특성 벡터로 변환\n",
    "\n",
    "# 1. 이메일 헤더 제거 \n",
    "# 2. 소문자 변환 \n",
    "# 3. 구두점 제거\n",
    "# 4. 공백, 특수문자 제거\n",
    "# 5. 모든 URL, 숫자 대체\n",
    "# 6. 어간 추출\n",
    "# 7. 단어 Map 생성 (Dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_data (3000,)\n"
     ]
    }
   ],
   "source": [
    "# word stemming in python\n",
    "# after stemming words, put data in dictionary\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# X should be pandas Series type\n",
    "def preprocess(X):\n",
    "    \n",
    "    # word stemming Object\n",
    "    porter = PorterStemmer()\n",
    "    \n",
    "    # Dictionary\n",
    "    word_map = {}\n",
    "    \n",
    "    cnt = 0\n",
    "    for i in range(len(X.values)):\n",
    "        tempArr = X.values[i].split(' ')\n",
    "        for j in range(len(tempArr)):\n",
    "\n",
    "            # word stemming\n",
    "            tempArr[j] = porter.stem(tempArr[j])\n",
    "            \n",
    "            # put data in dictionary\n",
    "            if tempArr[j] in word_map:\n",
    "                continue\n",
    "            else:\n",
    "                word_map[tempArr[j]] = cnt\n",
    "                cnt = cnt + 1\n",
    "            \n",
    "        X.values[i] = np.array(tempArr)\n",
    "    return X, word_map\n",
    "\n",
    "X_data, word_map = preprocess(X_data)\n",
    "print(\"X_data\", X_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_data.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Email as Feature Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "def convertToFeatureVector(X):\n",
    "    # make feature vector variable\n",
    "    x_len = len(X.values)\n",
    "    word_map_len = len(word_map.keys())\n",
    "    retArr = []\n",
    "    for i in range(len(X.values)):\n",
    "        temp = np.zeros(word_map_len)\n",
    "        for j in range(len(X.values[i])):\n",
    "            # set dictionary values\n",
    "            idx = word_map.get(X.values[i][j])\n",
    "            temp[idx] = 1\n",
    "        retArr.append(temp)\n",
    "    return np.array(retArr)\n",
    "\n",
    "X_feature_vec = convertToFeatureVector(X_data)\n",
    "print(X_feature_vec[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Train & Test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_feature_vec, y_data, stratify = y_data, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample Email Feature Vector\n",
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Machine Learning Models\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score :  100.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Score : \", round(clf.score(X_train, y_train)*100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94761905 0.97142857 0.98095238 0.96666667 0.96190476 0.98571429\n",
      " 0.97619048 0.98095238 0.98571429 0.9952381 ]\n"
     ]
    }
   ],
   "source": [
    "# with cross validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(clf, X_train, y_train, cv=10, scoring='accuracy')\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Set Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score :  97.56\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Score : \", round(clf.score(X_test, y_test)*100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
